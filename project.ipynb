{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analysis['100ma'] = data_analysis['Close'].rolling(window=100,min_periods=0).mean()\n",
    "# this is used to compute the average for pass 100 price (including itself)\n",
    "\n",
    "ax1 = plt.subplot2grid((6,1),(0,0),rowspan=5,colspan=1)\n",
    "ax2 = plt.subplot2grid((6,1),(5,0),rowspan=5,colspan=1,sharex=ax1)\n",
    "ax1.plot(data.index,data_analysis['Close'])\n",
    "ax1.plot(data.index,data_analysis['100ma'])\n",
    "ax2.plot(data.index,data_analysis['Total Trade Quantity'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ohlc = data_analysis['Close'].resample('10D').ohlc()\n",
    "data_volume = data_analysis['Total Trade Quantity'].resample('10D').sum()\n",
    "data_ohlc.reset_index(inplace=True) # the index should be 0 1 2 ....\n",
    "data_ohlc['Date'] = data_ohlc['Date'].map(mdates.date2num) # transfer datetime to timestamp\n",
    "\n",
    "ax1 = plt.subplot2grid((6,1),(0,0),rowspan=5,colspan=1)\n",
    "ax2 = plt.subplot2grid((6,1),(5,0),rowspan=5,colspan=1,sharex=ax1)\n",
    "ax1.xaxis_date()\n",
    "candlestick_ohlc(ax1,data_ohlc.values,width=2,colorup='g')\n",
    "ax2.fill_between(data_volume.index.map(mdates.date2num),data_volume.values,0)\n",
    "plt.show() ## candlestick graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculation of Relative Strength index(RSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TechIndicator = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative Strength Index\n",
    "# Avg(PriceUp)/(Avg(PriceUP)+Avg(PriceDown)*100\n",
    "# Where: PriceUp(t)=1*(Price(t)-Price(t-1)){Price(t)- Price(t-1)>0};\n",
    "#        PriceDown(t)=-1*(Price(t)-Price(t-1)){Price(t)- Price(t-1)<0};\n",
    "\n",
    "def rsi(values):\n",
    "    up = values[values>0].mean()\n",
    "    down = -1*values[values<0].mean()\n",
    "    return 100 * up / (up + down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Momentum_1D column for all 15 stocks.\n",
    "# Momentum_1D = P(t) - P(t-1)\n",
    "TechIndicator['Momentum_1D'] = (TechIndicator['Close']-TechIndicator['Close'].shift(1)).fillna(0)\n",
    "TechIndicator['RSI_14D'] = TechIndicator['Momentum_1D'].rolling(center=False, window=14).apply(rsi).fillna(0)\n",
    "TechIndicator.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of Bollinger Bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbands(price, length=30, numsd=2):\n",
    "    \"\"\" returns average, upper band, and lower band\"\"\"\n",
    "    #ave = pd.stats.moments.rolling_mean(price,length)\n",
    "    ave = price.rolling(window = length, center = False).mean()\n",
    "    #sd = pd.stats.moments.rolling_std(price,length)\n",
    "    sd = price.rolling(window = length, center = False).std()\n",
    "    upband = ave + (sd*numsd)\n",
    "    dnband = ave - (sd*numsd)\n",
    "    return np.round(ave,3), np.round(upband,3), np.round(dnband,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TechIndicator['BB_Middle_Band'], TechIndicator['BB_Upper_Band'], TechIndicator['BB_Lower_Band'] = bbands(TechIndicator['Close'], length=20, numsd=1)\n",
    "TechIndicator['BB_Middle_Band'] = TechIndicator['BB_Middle_Band'].fillna(0)\n",
    "TechIndicator['BB_Upper_Band'] = TechIndicator['BB_Upper_Band'].fillna(0)\n",
    "TechIndicator['BB_Lower_Band'] = TechIndicator['BB_Lower_Band'].fillna(0)\n",
    "TechIndicator.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of Aroon Oscillator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aroon(df, tf=25):\n",
    "    aroonup = []\n",
    "    aroondown = []\n",
    "    x = tf\n",
    "    while x< len(df['High']):\n",
    "        aroon_up = ((df['High'][x-tf:x].tolist().index(max(df['High'][x-tf:x])))/float(tf))*100\n",
    "        aroon_down = ((df['Low'][x-tf:x].tolist().index(min(df['Low'][x-tf:x])))/float(tf))*100\n",
    "        aroonup.append(aroon_up)\n",
    "        aroondown.append(aroon_down)\n",
    "        x+=1\n",
    "    return aroonup, aroondown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listofzeros = [0] * 25\n",
    "up, down = aroon(TechIndicator)\n",
    "aroon_list = [x - y for x, y in zip(up,down)]\n",
    "if len(aroon_list)==0:\n",
    "    aroon_list = [0] * TechIndicator.shape[0]\n",
    "    TechIndicator['Aroon_Oscillator'] = aroon_list\n",
    "else:\n",
    "    TechIndicator['Aroon_Oscillator'] = listofzeros+aroon_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of Price Volume Trend\n",
    "PVT = [((CurrentClose - PreviousClose) / PreviousClose) x Volume] + PreviousPVT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TechIndicator[\"PVT\"] = (TechIndicator['Momentum_1D']/ TechIndicator['Close'].shift(1))*TechIndicator['Total Trade Quantity']\n",
    "TechIndicator[\"PVT\"] = TechIndicator[\"PVT\"]-TechIndicator[\"PVT\"].shift(1)\n",
    "TechIndicator[\"PVT\"] = TechIndicator[\"PVT\"].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of Acceleration Bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download data from yahoo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data as pdr\n",
    "import fix_yahoo_finance as yf\n",
    "\n",
    "tickers_list = pd.read_csv('Yahoo_Ticker_Symbols.csv')\n",
    "\n",
    "tickers_list.drop(columns=['Category Name'],axis=1,inplace=True)\n",
    "\n",
    "tickers = list(tickers_list.Ticker)\n",
    "\n",
    "len(tickers)\n",
    "\n",
    "start_time = datetime.strptime('Jan 1 2000 ', '%b %d %Y ')\n",
    "start_time\n",
    "\n",
    "for i in range(0,21):\n",
    "    start = i * 5000\n",
    "    end = (i+1)*5000\n",
    "    Total_data_1 = pdr.get_data_yahoo(tickers=tickers[start:end],start=start_time,end=datetime.now())\n",
    "    closing_price = Total_data_1['Close']\n",
    "    volume = Total_data_1['Volume']\n",
    "    closing_price.to_csv('closing_part'+str(i)+'.csv')\n",
    "    volume.to_csv('volume_part'+str(i)+'.csv')\n",
    "    print('finished '+str(i)+'loop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input data as dataframe through pandas from csv files\n",
    "transfer dataframe index from str to datetime to filter data on Saturday and then output as pickle file to easy input in the future analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd \n",
    "path ='data' # use your path\n",
    "allFiles = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "clo_price_data = []\n",
    "vol_data = []\n",
    "for file in allFiles:\n",
    "    if file.startswith('data/closing'):\n",
    "        data = pd.read_csv(file).set_index('Date')\n",
    "        clo_price_data.append(data)\n",
    "        print('Successful import closing price file '+file)\n",
    "#     else:\n",
    "#         data = pd.read_csv(file).set_index('Date')\n",
    "#         vol_data.append(data)\n",
    "#         print('Successful import volume  file'+file)\n",
    "data_clo = pd.concat(clo_price_data, axis = 1, ignore_index = False,sort=False)\n",
    "data_clo.index = pd.to_datetime(data_clo.index)\n",
    "# data_clo.sort_index(inplace=True)\n",
    "# data_clo = data_clo.iloc[2:-1,:]\n",
    "\n",
    "clo_price_data  = []\n",
    "data_clo.index = pd.to_datetime(data_clo.index)\n",
    "\n",
    "data_clo[data_clo.index.weekday!=6].to_pickle('data/closing_price.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "yf.pdr_override()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clo_data = pd.read_pickle('data/closing_price.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clo_data.index = pd.to_datetime(clo_data.index)\n",
    "clo_data.sort_index(inplace=True)  ## transfet index from str to datetime and then sort by datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clo_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numNAs = (clo_data.isna().sum()/len(clo_data)).copy()\n",
    "\n",
    "numNAs.hist()\n",
    "\n",
    "stock_list =(numNAs<=0.2).copy()\n",
    "stock_list = stock_list[stock_list==True]\n",
    "\n",
    "cleaned_clo_data = clo_data[list(stock_list.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleand_data = cleaned_clo_data.iloc[cleaned_clo_data.index.weekday!=6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleand_data.to_pickle('data/closing_price.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "clearn_numNAs = cleaned_clo_data.isna().sum(axis=1)\n",
    "plt.plot(clearn_numNAs)\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Num of Nan values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "msno.bar(cleaned_clo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_clo_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_list = pd.read_csv('Yahoo_Ticker_Symbols.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exchange_list = tickers_list.Exchange.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ticker_df = tickers_list.set_index('Ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exchange_dict = {}\n",
    "for name in cleaned_clo_data.columns:\n",
    "    exchange = Ticker_df.loc[name].Exchange\n",
    "    if exchange not in Exchange_dict.keys():\n",
    "        Exchange_dict[exchange] = [name]\n",
    "    else:\n",
    "        Exchange_dict[exchange].append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = list(Exchange_dict.keys())\n",
    "ydata = [len(Exchange_dict[key]) for key in xdata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(8,5))\n",
    "plt.plot(xdata,ydata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seperate the dataframes into several dataframes by closing price and total price \n",
    "we can get volume value and closing price for all the tickers and then we try to drop sum tickers which have nan values more than 1% of total length and then fill nan value as previous price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Closed_price = Total_data['Close']\n",
    "missing_percent = Closed_price.isna().sum()/len(Closed_price)\n",
    "cleaned_cloing_price = Closed_price.drop(columns=missing_percent[missing_percent>0.01].index)\n",
    "cleaned_cloing_price.fillna(method='ffill',inplace=True)\n",
    "cleaned_cloing_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = cleaned_cloing_price.columns\n",
    "Volume = Total_data['Volume']\n",
    "cleaned_volume = Volume[columns_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_volume.to_csv('volume_data.csv')\n",
    "cleaned_cloing_price.to_csv('cloing_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## price return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_return(row):\n",
    "    r = np.log(row).diff()\n",
    "    return r "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_return = np.log(cleaned_cloing_price).diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(log_return.iloc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_cloing_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100; # number of time series\n",
    "T = 200  # time length\n",
    "q = N/T  # ratio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = cleaned_cloing_price.iloc[0:T+1, 0:N]\n",
    "ret = np.log(price).diff()[1:]\n",
    "corr_ret = np.corrcoef(ret.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, v = np.linalg.eig(corr_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_plus = (1 + np.sqrt(q))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_C_minus_C0(lambdas, v, lambda_plus):\n",
    "    # lambdas is a vector\n",
    "    # v is an eigenvector matrix\n",
    "    C_r = np.dot(np.dot(v[:,lambdas < lambda_plus], np.diag(lambdas[lambdas < lambda_plus])), v[:,lambdas < lambda_plus].T)\n",
    "    C_M = lambdas.max() * np.dot(v[:, lambdas.argmax()], v[:, lambdas.argmax()].T)\n",
    "    C_0 = C_r + C_M\n",
    "    C = np.dot(np.dot(v, np.diag(lambdas)), v.T)\n",
    "    return C - C_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import community \n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_s = np.abs(compute_C_minus_C0(u, v, lambda_plus))\n",
    "G = nx.Graph(C_s)\n",
    "part = community.best_partition(G)\n",
    "values = [part.get(node) for node in G.nodes()]\n",
    "\n",
    "nx.draw_spring(G, cmap = plt.get_cmap('jet'), node_color = values, node_size=30, with_labels=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph(C_s)\n",
    "partition  = community.best_partition(G)\n",
    "size = float(len(set(partition.values())))\n",
    "pos = nx.spring_layout(G)\n",
    "count = 0\n",
    "for com in set(partition.values()) :\n",
    "    count = count + 1.\n",
    "    list_nodes = [nodes for nodes in partition.keys()\n",
    "                                if partition[nodes] == com]\n",
    "    nx.draw_networkx_nodes(G, pos, list_nodes, node_size = 20,\n",
    "                                node_color = str(count / size))\n",
    "\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
